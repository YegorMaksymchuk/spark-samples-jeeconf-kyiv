# spark://127.0.0.1:7077 or local
spark.master=local

spark.application-name=Spark Presentation

spark.distributed-libraries=file:///Users/tmatyashovsky/Workspace/spark-samples-jeeconf-kyiv/spark-distributed-library/target/spark-distributed-library-1.0-SNAPSHOT-uber.jar

# Default cores assigned to each spark driver
spark.cores.max=2

# Amount of memory to assign to each executor process
spark.executor.memory=2g

# Serializer: org.apache.spark.serializer.JavaSerializer (default) or org.apache.spark.serializer.KryoSerializer
spark.serializer=org.apache.spark.serializer.KryoSerializer
spark.kryo.registrationRequired=false

# The number of partitions to use when shuffling data for joins or aggregations.
spark.sql.shuffle.partitions=10

# 2 options: localDataFilesLocation or hdfsDataFilesLocation
dataFilesLocation=localDataFilesLocation
spark.path-to-local-data=/Users/tmatyashovsky/Work/Spark-Presentation-JEEConf-Kyiv/csv
spark.path-to-hdfs-data=/Users/tmatyashovsky/Work/Spark-Presentation-JEEConf-Kyiv/parquet